{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36787944117144233"
     ]
    }
   ],
   "source": [
    "#Exercise 1: write a function that determines the reciprocal of a number without using division\n",
    "#Here we will find 1/e and show that it converges for x0 = 0.3 but not for x0 = 1.0\n",
    "\n",
    "function recip(d, x)\n",
    "    for i=1:100 x = x .* (2 - x .* d) end\n",
    "    return x\n",
    "end\n",
    "\n",
    "e = exp(1)\n",
    "\n",
    "println(recip(e, 0.3))\n",
    "println(recip(e, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newtmin (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sup_norm(x)                    #easier to read later code with this defined\n",
    "    return maximum(abs(x))\n",
    "end\n",
    "\n",
    "function newtmin_test_wolfe(f,g,new_f,new_g,alpha,p)\n",
    "    c1 = 1e-4                #Armijo condition constant\n",
    "    c2 = 0.9                 #curvature condition constant\n",
    "    \n",
    "    armijo = new_f - f <= c1*alpha*(g'*p)[1,1]           #satisfies Armijo condition?\n",
    "    curvature = abs(new_g'*p)[1,1] > -c2*(g'*p)[1,1]     #satisfies curvature condition?\n",
    "    valley = (new_g'*p)[1,1] < 0                         \n",
    "    return (armijo, curvature, valley)\n",
    "end\n",
    "\n",
    "function newtmin( obj, x0; maxIts=100, optTol=1e-6, BFGS=false)\n",
    "# Minimize a function f using Newtonâ€™s method.\n",
    "# obj: a function that evaluates the objective value, gradient, and Hessian at a point x, i.e.,\n",
    "#    (f, g, H) = obj(x)\n",
    "# x0: starting point.\n",
    "# maxIts (optional): maximum number of iterations.\n",
    "# optTol (optional): optimality tolerance based on ||grad(x)|| <= optTol*||grad(x0)||\n",
    "# BFGS (optional): set as true to use BFGS algorithm ( = false by default)\n",
    "\n",
    "    verbose = false\n",
    "    \n",
    "    its = 0;\n",
    "    x = x0;\n",
    "    \n",
    "    if(BFGS)\n",
    "        (f,g,_) = obj(x)\n",
    "        n = size(g)[1]\n",
    "        H_inv = eye(n)/norm(g)        #approximate Hessian as scaled identity\n",
    "    else\n",
    "        (f,g,H) = obj(x)     #evaluate gradient, et al\n",
    "    end\n",
    "      \n",
    "    ngx0 = sup_norm(g)           #need to keep this value for stopping condition\n",
    "    \n",
    "    if(ngx0 > optTol^2)      #trap for low grad(x0)\n",
    "        \n",
    "        while(its < maxIts && sup_norm(g) > optTol*(ngx0))\n",
    "            \n",
    "            Hessian_modded = false\n",
    "            \n",
    "            if(BFGS)\n",
    "                p = -H_inv * g\n",
    "            else\n",
    "                p = -H \\ g           #compute descent direction\n",
    "            end\n",
    "            \n",
    "            alpha = 1\n",
    "            alpha_min = 0\n",
    "            alpha_max = 1\n",
    "            \n",
    "            new_x = x + alpha*p  #trial step\n",
    "            \n",
    "            \n",
    "            (new_f,new_g,_) = obj(new_x)\n",
    "            \n",
    "            (armijo, curvature, valley) = newtmin_test_wolfe(f,g,new_f,new_g,alpha,p)\n",
    "                \n",
    "            while(!armijo || !valley)\n",
    "                \n",
    "                if(!Hessian_modded && !BFGS)\n",
    "                    #force the Hessian to be positive definite\n",
    "                    \n",
    "                    if(verbose) print(\"H\"); end\n",
    "                    \n",
    "                    Hessian_modded = true\n",
    "                \n",
    "                    (V, S) = eig(H)                    #decompose H\n",
    "                \n",
    "                    if(minimum(V) < 0)                 #if not positive definite\n",
    "                    \n",
    "                        #V[V .<= 0] = maximum(V)        #do not explore areas of negative curvature\n",
    "                        \n",
    "                        V = V + abs(1.01*minimum(V))\n",
    "                    \n",
    "                        V_inv = diagm(1 ./ V)\n",
    "                    \n",
    "                        p = -S*V_inv*S'*g              #recalculate p    \n",
    "                        \n",
    "                    end\n",
    "                \n",
    "                else    #Hessian was already fixed\n",
    "                \n",
    "                    if(!armijo)\n",
    "                        alpha_max = alpha                 #not enough decrease; try a smaller step\n",
    "                        if(verbose) print(\"A\"); end\n",
    "                    elseif(!curvature)\n",
    "                        if(verbose) print(\"C\"); end\n",
    "                        break                             #decrease is too slow to worry about hills/valleys\n",
    "                    else\n",
    "                        if(verbose) print(\"V\"); end\n",
    "                        alpha_min = alpha                 #going to land on a hill, try to speed over it\n",
    "                    end\n",
    "                                \n",
    "                    alpha = 0.5*(alpha_max + alpha_min)   #try an intermediate value\n",
    "                end\n",
    "                \n",
    "                new_x = x + alpha*p                   #trial step\n",
    "            \n",
    "                (new_f,new_g,_) = obj(new_x)      #evaluate new gradient, et al\n",
    "                \n",
    "                \n",
    "                (armijo, curvature, valley) = newtmin_test_wolfe(f,g,new_f,new_g,alpha,p)\n",
    "            \n",
    "                if (alpha_max - alpha_min < 0.01)       #interval is too narrow\n",
    "                    if(verbose) print(\"B\"); end\n",
    "                    break        #break out of loop; just take a step and hope for the best\n",
    "                end\n",
    "            \n",
    "            end        #terminate linesearch\n",
    "            \n",
    "            \n",
    "            #calculate Hessian\n",
    "            if (BFGS)\n",
    "                y = new_g - g\n",
    "                s = alpha*p\n",
    "                ro = 1 / (y'*s)[1,1]\n",
    "                H_inv = (eye(n) - ro*s*y')*H_inv*(eye(n) - ro*y*s') + ro*s*s'    \n",
    "            else\n",
    "                (_,_,H) = obj(new_x)\n",
    "            end\n",
    "            \n",
    "            x = new_x           #commit to the step\n",
    "            f = new_f\n",
    "            g = new_g\n",
    "            \n",
    "            Hessian_modded = false\n",
    "            \n",
    "            its = its + 1\n",
    "            \n",
    "        end\n",
    "    \n",
    "    else\n",
    "        println(\"||grad(x0)|| is already < \", optTol^2)\n",
    "    end\n",
    "    \n",
    "    return (x, its)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations for Newton/BFGS\n",
      "\n",
      "Problem #1:  11, 28\n",
      "Problem #2:  FAIL, 40\n",
      "Problem #3:  2, 5\n",
      "Problem #4:  88, 135\n",
      "Problem #5:  13, 75\n",
      "Problem #6:  17, 17\n",
      "Problem #7:  FAIL, 56\n",
      "Problem #8:  11, 18\n",
      "Problem #9:  32, 113\n",
      "Problem #10:  8, 28\n",
      "Problem #11:  31, 36\n",
      "Problem #12:  14, 51\n",
      "Problem #13:  105, 62\n",
      "Problem #14:  FAIL, 40\n",
      "Problem #15:  FAIL, 49\n",
      "Problem #16:  9, 14\n",
      "Problem #17:  36, 35\n",
      "Problem #18:  FAIL, 215\n"
     ]
    }
   ],
   "source": [
    "using Toms566\n",
    "\n",
    "#test the algorithm on Toms566\n",
    "\n",
    "max_its = 2000\n",
    "tol = 1e-6\n",
    "\n",
    "println(\"Number of iterations for Newton/BFGS\\n\");\n",
    "\n",
    "for number = 1:18\n",
    "       \n",
    "    p = Problem(number)\n",
    "\n",
    "    (x, its) =\n",
    "        newtmin(xk -> (p.obj(xk), p.grd(xk), p.hes(xk)), p.x0; maxIts = max_its, optTol = tol, BFGS = false)\n",
    "                                    #newtmin(anonymous function, p.x0)\n",
    "    (x_bfgs, its_bfgs) =\n",
    "        newtmin(xk -> (p.obj(xk), p.grd(xk), p.hes(xk)), p.x0; maxIts = max_its, optTol = tol, BFGS = true)\n",
    "    \n",
    "    g = p.grd(x)\n",
    "    g_bfgs = p.grd(x_bfgs)\n",
    "    g0 = p.grd(p.x0)\n",
    "    \n",
    "    print(\"Problem #\", number, \":  \")\n",
    "    \n",
    "    if(sup_norm(g)/sup_norm(g0) <= tol || sup_norm(g0) <= tol^2)\n",
    "        print(its)\n",
    "    else\n",
    "        print(\"FAIL\")\n",
    "    end\n",
    "    \n",
    "    print(\", \")\n",
    "    \n",
    "    if(sup_norm(g_bfgs)/sup_norm(g0) <= tol || sup_norm(g0) <= tol^2)\n",
    "        print(its_bfgs)\n",
    "    else\n",
    "        print(\"FAIL\")\n",
    "    end\n",
    "    \n",
    "    println()\n",
    "end\n",
    "\n",
    "sleep(0.1)    #to keep output from bleeding into the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.11",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
